<html lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
  <meta name="keywords" content=
  "pumarola, albert, deep learning, computer vision, computer graphics, machine learning, artificial intelligence, IRI, slam, lines">
  <meta charset="UTF-8">
  <meta name="description" content=
  "Low textured scenes are well known to be  one of the main Achilles heels of geometric computer vision algorithms relying on point correspondences, and in particular for visual SLAM. Yet, there are many environments in which, despite being low textured, one can still reliably estimate  line-based geometric primitives, for instance in  city and  indoor scenes, or in the so-called ``Manhattan worlds'', where structured edges are predominant. In this paper we propose a solution to handle these situations. Specifically, we build upon ORB-SLAM, presumably the  current state-of-the-art solution both in terms of accuracy as efficiency, and extend its formulation to simultaneously handle both point and line correspondences. We propose a solution that can even work when most of the  points are vanished out from the input images, and, interestingly it can be initialized from solely the detection of line correspondences in three consecutive frames. We thoroughly evaluate our approach and the new initialization strategy on the TUM RGB-D benchmark and demonstrate that the use of lines does not only improve the performance of the original ORB-SLAM solution in poorly textured frames, but also systematically improves it in sequence frames combining points and lines, without compromising the efficiency.">
  <meta name="author" content="Albert Pumarola">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#0074D9">
  <title>Albert Pumarola - PL-SLAM</title>
  <link rel="stylesheet" type="text/css" href="../../../style.css" media="screen">
</head>
<body>
  <div id="page">
    <div id="menubar">
      <h2><a lang="en" href="../../">Home</a></h2>
      <h2><a lang="en" href="../">Research</a></h2>
      <ul>
        <li><span class="active" title="You're here.">PL-SLAM</span></li>
      </ul>
      <h2><a lang="en" href="../../publications/">Publications</a></h2>
    </div>
    <div id="main">
      <h1 lang="en">PL-SLAM</h1>
      <div id="project">
        <div id="authors" lang="en">
          <p><strong>Albert Pumarola</strong>, 
              <a href="https://sites.google.com/site/alexandervakhitov/">Alexander Vakhitov</a>, 
              <a href="http://www.iri.upc.edu/people/aagudo/">Antonio Agudo</a>,
              <a href="http://www.iri.upc.edu/people/sanfeliu/">Alberto Sanfeliu</a>,
              <a href="http://www.iri.upc.edu/people/fmoreno/">Francesc Moreno-Noguer</a>
          </p>
        </div>
        <center><img src="../../../images/2017/pl-slam/teaser.jpg" height="500" width="900" alt="PL-SLAM" class="teaser"></center>
        <div class="abstract" lang="en">
          <p>We present a novel technique to simplify sketch drawings based on learning a series of
          convolution operators. In contrast to existing approaches that require vector images as
          input, we allow the more general and challenging input of rough raster sketches such as
          those obtained from scanning pencil sketches. We convert the rough sketch into a
          simplified version which is then amendable for vectorization. This is all done in a fully
          automatic way without user intervention. Our model consists of a fully convolutional
          neural network which, unlike most existing convolutional neural networks, is able to
          process images of any dimensions and aspect ratio as input, and outputs a simplified
          sketch which has the same dimensions as the input image. In order to teach our model to
          simplify, we present a new dataset of pairs of rough and simplified sketch drawings. By
          leveraging convolution operators in combination with efficient use of our proposed
          dataset, we are able to train our sketch simplification model. Our approach naturally
          overcomes the limitations of existing methods, e.g., vector images as input and long
          computation time; and we show that meaningful simplifications can be obtained for many
          different test cases. Finally, we validate our results with a user study in which we
          greatly outperform similar approaches and establish the state of the art in sketch
          simplification of raster images.</p>
        </div>
        <div id="content">
          <ul id="filter">
<!--            <li><a href="http://server_name:port/"><span lang="en">Online demo</span></a></li>-->
          </ul>
          <div lang="en">
            <h2 id="model">Spotlight Video</h2>
            <center>
               <div class="videocontainer">
                  <div class="videowrapper"> 
                     <iframe width="560" height="315" align="center" src="//www.youtube.com/embed/_1uDk8enoAQ" seamless="" allowfullscreen=""></iframe>
                  </div>  
               </div>
            </center>
          </div>
            <p>The video shows an evaluation of PL-SLAM and the new initialization strategy 
               on a TUM RGB-D benchmark sequence. The sequence selected is the same as the 
               one used to generate Figure 1 of the paper. </p>

                <p class="small">Legend:</p>
            <ul>
                <li>Map: estimated camera position (green box), camera key frames
               (blue boxes), point features (green points) and line features (red-blue endpoints)</li>
                <li>Current Frame: point features (green boxes) and line features (red-blue endpoints)</li>
            </ul>
          </div>
        </div>
        <h2><span lang="en">Publications</span></h2>
        <div class="publications">
          <h3 class="conference"><span lang="en">2017</span></h3>
          <ul class="publist">
            <li class="conference">
            <div class="details">
              <a href="../../publications/none.pdf"><img src=
              "../../images/2017/pl-slam/pl-slam_icra.jpg" height="100" width="100" alt=
              "PL-SLAM: Real-Time Monocular Visual SLAM with Points and Lines" class="thumb"></a>
              <ul class="pub">
                <li class="pubtitle">PL-SLAM: Real-Time Monocular Visual SLAM with Points and Lines</li>
                <li class="pubauthor">Albert Pumarola, Alexander Vakhitov, Antonio Agudo, Alberto Sanfeliu and Francesc Moreno-Noguer </li>
                <li class="pubbooktitle">IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017.</li>
                <li>
                  <div class="list_buttons">
                    <a class="bibtexLink" href="../../publications/none.pdf">PDF</a>
                    <a class="bibtexLink" onclick="return toggle('/publications/PumarolaICPR2017/abs',this)"><span lang="en">Abstract</span></a>
                    <a class="bibtexLink" onclick="return toggle('/publications/PumarolaICPR2017/bib',this)">Bibtex</a>
                    <a class="bibtexLink" onclick="">code (to be released)</a>
                  </div>
                </li>
              </ul>
            </div>
            <div style="display: none;" class="abstractbox" id="/publications/PumarolaICPR2017/abs">
              <p>Low textured scenes are well known to be  one of the main Achilles heels of geometric computer vision algorithms relying on point correspondences, and in particular for visual SLAM. Yet, there are many environments in which, despite being low textured, one can still reliably estimate  line-based geometric primitives, for instance in  city and  indoor scenes, or in the so-called ``Manhattan worlds'', where structured edges are predominant. In this paper we propose a solution to handle these situations. Specifically, we build upon ORB-SLAM, presumably the  current state-of-the-art solution both in terms of accuracy as efficiency, and extend its formulation to simultaneously handle both point and line correspondences. We propose a solution that can even work when most of the  points are vanished out from the input images, and, interestingly it can be initialized from solely the detection of line correspondences in three consecutive frames. We thoroughly evaluate our approach and the new initialization strategy on the TUM RGB-D benchmark and demonstrate that the use of lines does not only improve the performance of the original ORB-SLAM solution in poorly textured frames, but also systematically improves it in sequence frames combining points and lines, without compromising the efficiency.</p>
            </div>
            <div style="display: none;" class="bibtex" id="/publications/PumarolaICPR2017/bib">
              <pre>@InProceedings{PumarolaICRA2017,
   author = {Albert Pumarola and Alexander Vakhitov and Antonio Agudo and Alberto Sanfeliu and Francesc Moreno-Noguer},
   title = {{PL-SLAM: Real-Time Monocular Visual SLAM with Points and Lines}},
   booktitle = "International Conference in Robotics and Automation (ICRA)",
   year = 2017
}</pre>
            </div>
          </li>
          </ul>
        </div>
        <div id="content">
          <div lang="en">
            <h2 id="model">Acknowledgments</h2>
            <p>This work has been partially supported by the EU project AEROARMS H2020-ICT-2014-1-644271, by the MINECO projects  RobInstruct TIN2014-58178-R, by the Spanish Ministry of Science and Innovation project Rob-Int-Coop DPI2013-42458-P and by the ERA-Net Chistera project I-DRESS PCIN-2015-147.</p>
          </div>
        </div>
      </div>
    </div>
  </div>
  <script src="//ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js">
  </script> 
  <script>
  window.jQuery || document.write('<script src="../../../jquery.js"><\/script>')
  </script> 
  <script type="text/javascript" src="../../../site.js">
  </script> 
  <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-90616851-1', 'auto');
      ga('send', 'pageview');
  </script>
</body>
</html>
