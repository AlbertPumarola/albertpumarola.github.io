<html lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
  <meta name="keywords" content=
  "pumarola, albert, deep learning, computer vision, computer graphics, machine learning, artificial intelligence, IRI, GAN, expressions, face, facial, editing, modification, face expressions, face editing, face manipulation, GANimation, GAN animation">
  <meta charset="UTF-8">
  <meta name="description" content=
  "Recent advances in Generative Adversarial Networks (GANs) have shown remarkable improvements in the  task of facial expression synthesis. The most successful results are  obtained by StarGAN, an architecture that conditions GANs'  generation process with images of a specific domain, namely a set of images of persons sharing the same expression. While effective, this approach only allows generating a discrete number of expressions, determined by the  content of the dataset. In this paper, instead, we introduce a novel GAN conditioning scheme based on  Action Units (AU) annotations, which describe in a continuous manifold  the  anatomical facial  movements defining a human expression. Our approach permits controlling the magnitude of activation of each AU and combine several of them. Additionally, we propose a fully unsupervised strategy to train the model, that requires only images annotated with their activated AUs, and exploit attention mechanisms that make our network robust to changing backgrounds and illumination conditions. Extensive evaluation show that our approach goes beyond competing conditional generators both in the capability to synthesize a much wider range of expressions ruled by anatomically feasible muscle movements, as in the capacity of dealing with images in the wild.">
  <meta name="author" content="Albert Pumarola">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#0074D9">
  <title>Albert Pumarola - Person-Synthesis</title>
  <link rel="stylesheet" type="text/css" href="../../../style.css" media="screen">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    <link rel="canonical" href="https://www.albertpumarola.com/research/GANimation/index.html" />

    
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  </script>
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
  <a href="https://github.com/albertpumarola/GANimation">
		<img style="position: fixed; top: 0; right: 0; border: 0; z-index: 11;" src="https://s3.amazonaws.com/github/ribbons/forkme_right_red_aa0000.png" alt="Fork me on GitHub" alt="Fork me on GitHub" />
	</a>
</head>
    
    
    
<body>
  <div id="page">
    <div id="menubar">
      <h2><a href="../../#page" lang="en">Home</a></h2>
      <h2><a href="../../#publications" lang="en">Publications</a></h2>
      <h2><a href="../../#projects" lang="en">Projects</a></h2>
    </div>
    <div id="main">
      <h1 lang="en">GANimation: Anatomically-aware Facial Animation from a Single Image</h1>
      <div id="project">
        <div id="authors" lang="en">
          <p><strong>Albert Pumarola</strong>, 
              <a href="https://www.iri.upc.edu/people/aagudo/">Antonio Agudo</a>,
              <a href="https://www2.ece.ohio-state.edu/~aleix/">Aleix M. Martinez</a>,
              <a href="https://www.iri.upc.edu/people/sanfeliu/">Alberto Sanfeliu</a>,
              <a href="https://www.iri.upc.edu/people/fmoreno/">Francesc Moreno-Noguer</a>
          </p>
        </div>
        <center><img src="../../../images/2018/GANimation/teaser.png" alt="GANimation"  class="teaser"> </center>
        <div class="abstract" lang="en">
          <p> We introduce a novel GAN conditioning scheme based on Action Units (AU) annotations, which describe in a continuous manifold the anatomical facial movements defining a human expression. Our approach permits controlling the magnitude of activation of each AU and combine several of them.</p>
        </div>
        <h2 id="method"><a name="method">Method</a></h2>
            <center><img src="../../../images/2018/GANimation/model.png" height="358" width="1000" alt="GANimation"></center>
            <p>The proposed architecture consists of two main modules. On the one hand, a generator $G(\mathbf{I}_{\mathbf{y}_r}|\mathbf{y}_g)$ is trained to realistically transform the facial expression in image $\mathbf{I}_{\mathbf{y}_r}$ to the desired $\mathbf{y}_g$. On the other hand, we use a critic $D(\mathbf{I}_{\mathbf{y}_g})$ to evaluate the quality of the generated image as well as its expression. Note that $G$ is applied twice, first to map the input image $\mathbf{I}_{\mathbf{y}_r}\rightarrow \mathbf{I}_{\mathbf{y}_g}$, and then to render it back $\mathbf{I}_{\mathbf{y}_g}\rightarrow \hat{\mathbf{I}}_{\mathbf{y}_r}$. <br> 
            <center><img src="../../../images/2018/GANimation/face_gen_eq.png" width="600" alt="GANimation"></center>
            One key ingredient of our system is to make $G$ focus only on those regions of the image that are responsible of synthesizing the novel expression and keep the rest elements of the image such as hair, glasses, hats or jewelery untouched. Concretely, instead of regressing a full image, our generator outputs two masks, a color mask $\mathbf{C}$ and attention mask $\mathbf{A}$. The attention is learned in an unsupervised manner. </p>
        <h2 id="results">
            
        <a name="results">Results</a></h2>
        <center><img src="../../../images/2018/GANimation/results.png" height="834" width="691" alt="GANimation"></center>
        <div lang="en">
          <p> Examples of expression animation in a continuous domain. In these examples, we are given solely the left-most input image $\mathbf{I}_{\mathbf{y}_r}$ (highlighted by a green square), and the parameter $\alpha$ controls the degree of activation of the target action units involved in a smiling-like expression. Additionally, our system can handle images with unnatural illumination conditions, such as the example in the bottom row.</p>
        </div>
        <div class="picwrapper">
            <div class="pic"><img src="../../../images/2018/GANimation/face1_cyc.gif" ></div>
            <div class="pic"><img src="../../../images/2018/GANimation/face2_cyc.gif" ></div>
            <div class="pic"><img src="../../../images/2018/GANimation/face3_cyc.gif" ></div>
            <div class="pic"><img src="../../../images/2018/GANimation/face4_cyc.gif" ></div>
            <div class="pic"><img src="../../../images/2018/GANimation/face5_cyc.gif" ></div>
            <div class="pic"><img src="../../../images/2018/GANimation/face6_cyc.gif" ></div>
        </div>
          
        <h2><span lang="en">News and Tech Websites</span></h2>
        <center><ul class="newsimages">
            <li class="imagegroup newsentry">
            <a href="https://www.elconfidencial.com/ultima-hora-en-vivo/2018-10-11/investigadores-crean-primer-sistema-de-reproduccion-de-expresiones-faciales_1642063/"><img src="../../../images/media/elconfidencial.png" alt="El Confidencial"></a>
            </li>
            <li class="imagegroup newsentry">
            <a href="https://agencias.abc.es/agencias/noticia.asp?noticia=2939978"><img src="../../../images/media/abc.png" alt="ABC"></a>
            </li>
            <li class="imagegroup newsentry">
            <a href="https://www.lavanguardia.com/vida/20181011/452301706478/investigadores-crean-primer-sistema-de-reproduccion-de-expresiones-faciales.html?utm_campaign=botones_sociales&utm_source=twitter&utm_medium=social"><img src="../../../images/media/lavanguardia.png" alt="La Vanguardia"></a>
            </li>
            <li class="imagegroup newsentry">
            <a href="https://acceso360.acceso.com/upc/es-ES/?mod=TrackingPressViewer&task=default&external=1&companyNewsId=515277444&newsDate=1539295200&sig=1608f54b58891f7351d7d77c77e7565cd2ccf30a63197318bd96106e88523769"><img src="../../../images/media/diariadegirona.png" alt="Diari de Girona"></a>
            </li>
            <li class="imagegroup newsentry">
            <a href="https://acceso360.acceso.com/upc/es-ES/?mod=TrackingPressViewer&task=default&external=1&companyNewsId=515775848&newsDate=1539640800&sig=75f067eddc1eb07c15ad1077aaebf73702b8396eb6ee0e2c70bceca8187f36ba"><img src="../../../images/media/elmundo.png" alt="El Mundo"></a>
            </li>
            <li class="imagegroup newsentry">
            <a href="https://www.hoy.es/agencias/201810/11/investigadores-crean-primer-sistema-1272337.html"><img src="../../../images/media/hoy.png" alt="Hoy"></a>
            </li>
            <li class="imagegroup newsentry">
            <a href="https://www.larioja.com/agencias/201810/11/investigadores-crean-primer-sistema-1272337.html"><img src="../../../images/media/larioja.png" alt="La Rioja"></a>
            </li>
            <li class="imagegroup newsentry">
            <a href="https://www.diariovasco.com/agencias/201810/11/investigadores-crean-primer-sistema-1272337.html"><img src="../../../images/media/eldiariovasco.png" alt="El Diario Vasco"></a>
            </li>
            
            <li class="imagegroup newsentry">
            <a href="https://www.techleer.com/articles/540-simple-pytorch-implementation-of-ganimation-eccv-2018-oral/"><img src="../../../images/media/techleer.png" alt="TechLeer"></a>
            </li>
            <li class="imagegroup newsentry">
            <a href="https://medium.com/@hfdtsinghua/ganimation-anatomically-aware-facial-animation-from-a-single-image-5b49160061c8"><img src="../../../images/media/medium.png" alt="Medium"></a>
            </li>
            <li class="imagegroup newsentry">
            <a href="https://www.prevencionintegral.com/actualidad/noticias/2018/10/17/iri-universitat-politecnica-catalunya-crea-primer-sistema-para-reproducir-todas-expresiones-faciales"><img src="../../../images/media/prevencionintegral.png" alt="Prevencion Integral"></a>
            </li>
            <li class="imagegroup newsentry">
            <a href="https://noticiasdelaciencia.com/art/30269/un-equipo-del-iri-csic-upc-crea-el-primer-sistema-para-reproducir-todas-las-expresiones-faciales-y-de-manera-continua-a-partir-de-una-sola-imagen"><img src="../../../images/media/noticiasdelaciencia.png" alt="Noticias de la Ciencia"></a>
            </li>
            <li class="imagegroup newsentry">
            <a href="https://neurohive.io/en/state-of-the-art/anatomically-aware-facial-animation-from-a-single-image/"><img src="../../../images/media/neurohive.jpg" alt="neurohive"></a>
            </li>
            <li class="imagegroup newsentry">
            <a href="https://www.topbots.com/most-important-ai-computer-vision-research/#ai-cv-paper-2018-7"><img src="../../../images/media/topbots.png" alt="topbots"></a>
            </li>
            <li class="imagegroup newsentry">
            <a href="https://www.upc.edu/es/sala-de-prensa/noticias/un-equipo-del-iri-csic-upc-crea-el-primer-sistema-para-reproducir-todas-las-expresiones-faciales-y-de-manera-continua-a-partir-de-una-sola-imagen"><img src="../../../images/media/upc.png" alt="UPC"></a>
            </li>
            <li class="imagegroup newsentry">
            <a href="https://www.dicat.csic.es/dicat/en/noticias-2/noticias/752-todas-las-expresiones-faciales-y-de-manera-continua-a-partir-de-una-sola-imagen"><img src="../../../images/media/csic.png" alt="CSIC"></a>
            </li>
        </ul></center>
          
        <h2><span lang="en">BibTex</span></h2>
        <div class="alert" lang="en">
            @article{Pumarola_ijcv2019,<br>
                &nbsp;&nbsp;&nbsp;&nbsp;title={GANimation: One-Shot Anatomically Consistent Facial Animation},<br>
                &nbsp;&nbsp;&nbsp;&nbsp;author={A. Pumarola and A. Agudo and A.M. Martinez and A. Sanfeliu and F. Moreno-Noguer},<br>
                &nbsp;&nbsp;&nbsp;&nbsp;booktitle={International Journal of Computer Vision (IJCV)},<br>
                &nbsp;&nbsp;&nbsp;&nbsp;year={2019}<br>
            }
        </div>
        <h2><span lang="en">Publications</span></h2>
        <div class="publications">
        <ul class="publist">
            <li class="article">
            <div class="details">
              <a href="https://rdcu.be/bPuaJ" target="_blank"><img src=
              "../../images/2019/GANimation/thumbnail.png" height="194" width="131" alt=
              "GANimation: One-Shot Anatomically Consistent Facial Animation" class="thumb"></a>
              <ul class="pub">
                <li class="pubtitle">GANimation: One-Shot Anatomically Consistent Facial Animation    </li>
                <li class="pubauthor">A. Pumarola, A. Agudo, A. M. Martinez, A. Sanfeliu and F. Moreno-Noguer </li> 
                <li class="pubbooktitle">International Journal of Computer Vision (IJCV), 2019. </li>                <li>
                 <div class="list_buttons">
                    <a class="bibtexLink" href="https://rdcu.be/bPuaJ" target="_blank">PDF</a>
                    <a class="bibtexLink" href="https://github.com/albertpumarola/GANimation.git" target="_blank"><i class="fa fa-github"></i> Code</a>
                    <a class="bibtexLink" onclick="return toggle('/publications/PumarolaGanimationIJCV19/bib',this)">Bibtex</a>
                  </div>
                </li>
              </ul>
            </div>
            <div style="display: none;" class="bibtex" id="/publications/PumarolaGanimationIJCV19/bib">
              <pre>@article{Pumarola_ijcv2019, 
  title = {GANimation: One-Shot Anatomically Consistent Facial Animation}, 
  author = {A. Pumarola and A. Agudo and A.M. Martinez and A. Sanfeliu and F. Moreno-Noguer}, 
  booktitle = {International Journal of Computer Vision (IJCV)}, 
  year = {2019} 
}</pre>
            </div>
          </li>
        </ul>
        <ul class="publist">
          <li class="conference">
            <div class="details">
              <a href="https://arxiv.org/abs/1807.09251"  target="_blank"><img src=
              "../../images/2018/GANimation/thumbnail.png" height="194" width="131" alt=
              "GANimation: Anatomically-aware Facial Animation from a single image" id="GANimation_eccv" class="thumb"></a>
              <ul class="pub">
                <li class="pubtitle">GANimation: Anatomically-aware Facial Animation from a Single Image</li>
                <li class="pubauthor">A. Pumarola, A. Agudo, A. M. Martinez, A. Sanfeliu and F. Moreno-Noguer </li> 
                <li class="pubbooktitle">European Conference on Computer Vision (ECCV), 2018. </li> 
                <li><a href="https://eccv2018.org/awards-2/"  target="_blank"><font color="red"><b>[Best Paper Award Honorable Mention]</b></font></a></li>
                <li>
                 <div class="list_buttons">
                    <a class="bibtexLink" href="https://arxiv.org/abs/1807.09251" target="_blank">PDF</a>
                    <a class="bibtexLink" href="https://github.com/albertpumarola/GANimation.git" target="_blank"><i class="fa fa-github"></i> Code</a>
                    <a class="bibtexLink" onclick="return toggle('/publications/PumarolaGanimationECCV18/bib',this)">Bibtex</a>
                  </div>
                </li>
              </ul>
            </div>
            <div style="display: none;" class="bibtex" id="/publications/PumarolaGanimationECCV18/bib">
              <pre>@inproceedings{pumarola2018ganimation,
  title={GANimation: Anatomically-aware Facial Animation from a Single Image},
  author={A. Pumarola and A. Agudo and A.M. Martinez and A. Sanfeliu and F. Moreno-Noguer},
  booktitle={Proceedings of the European Conference on Computer Vision (ECCV)},
  year={2018}
}</pre>
            </div>
          </li>
        </ul>
    

        <div id="content">
          <div lang="en">
            <h2 id="model">Acknowledgments</h2>
            <p>This work is partially supported by the Spanish Ministry of Economy and Competitiveness under projects HuMoUR TIN2017-90086-R, ColRobTransp DPI2016-78957 and Mar\'ia de Maeztu Seal of Excellence MDM-2016-0656; by the EU project AEROARMS ICT-2014-1-644271; and by the Grant R01-DC- 014498 of the National Institute of Health. We also thank Nvidia for hardware donation under the GPU Grant Program. </p>
          </div>
        </div>
      </div>
    </div>
  </div>
  </div>  
      
  <script src="//ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js">
  </script> 
  <script>
  window.jQuery || document.write('<script src="../../../jquery.js"><\/script>')
  </script> 
  <script type="text/javascript" src="../../../site.js">
  </script> 
  <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-90616851-1', 'auto');
      ga('send', 'pageview');
  </script>
</body>
</html>
