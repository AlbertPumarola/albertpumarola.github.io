<html lang="en">
<head>
  <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
  <meta name="keywords" content=
  "pumarola, albert, deep learning, computer vision, computer graphics, machine learning, artificial intelligence, IRI, GAN, 3DPeople, reconstruction, cloth, people, geometry image, dataset, people dataset, 3D dataset, human dataset, surreal, optical flow, 3D, cloth, body part, segmentation, squeleton, depth, normals">
  <meta charset="UTF-8">
  <meta name="description" content=
  "Recent advances in 3D human shape estimation build upon parametric representations that model very well the shape of the naked body, but are not appropriate to represent the clothing geometry. In this paper, we present an approach to model dressed humans and predict their geometry from single images. We contribute in three fundamental aspects of the problem, namely, a new dataset, a novel shape parameterization algorithm and an end-to-end deep generative network for predicting shape.First, we present 3DPeople, a large-scale synthetic dataset with 2.5 Million photo-realistic images of 80 subjects performing 70 activities and wearing diverse outfits. Besides providing textured 3D meshes for clothes and body, we annotate the dataset with segmentation masks, skeletons, depth, normal maps and optical flow. All this together makes 3DPeople suitable for a plethora of tasks. We then represent the 3D shapes using 2D geometry images. To build these images we propose a novel spherical area-preserving parameterization algorithm based on the optimal mass transportation method. We show this approach to improve existing spherical maps which tend to shrink the elongated parts of the full body models such as the arms and legs, making the geometry images incomplete. Finally, we design a multi-resolution deep generative network that, given an input image of a dressed human, predicts his/her geometry image (and thus the clothed body shape) in an end-to-end manner. We obtain very promising results in jointly capturing body pose and clothing shape, both for synthetic validation and on the wild images.">
  <meta name="author" content="Albert Pumarola">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="theme-color" content="#0074D9">
  <title>Albert Pumarola - 3DPeople</title>
  <link rel="stylesheet" type="text/css" href="../../../style.css" media="screen">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <link rel="canonical" href="https://www.albertpumarola.com/research/3DPeople/index.html" />
    
  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]}});
  </script>
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.3/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
</head>
    
    
    
<body>
  <div id="page">
    <div id="menubar">
      <h2><a href="../../#page" lang="en">Home</a></h2>
      <h2><a href="../../#publications" lang="en">Publications</a></h2>
      <h2><a href="../../#projects" lang="en">Projects</a></h2>
    </div>
    <div id="main">
      <h1 lang="en">3DPeople: Modeling the Geometry of Dressed Humans</h1>
      <div id="project">
        <div id="authors" lang="en">
          <p> <strong>Albert Pumarola</strong>, 
              <a href="https://www.iri.upc.edu/staff/jsanchez">Jordi Sanchez</a>,
              <a href="https://scholar.harvard.edu/choi/home">Gary P. T. Choi</a>,
              <a href="https://www.iri.upc.edu/people/sanfeliu/">Alberto Sanfeliu</a>,
              <a href="https://www.iri.upc.edu/people/fmoreno/">Francesc Moreno-Noguer</a>
          </p>
        </div>
          <center><a href="#"><img src="../../../images/2019/3DPeople/teaser.jpg" alt="3DPeople" class="teaser"></a> </center>
        <div class="abstract" lang="en">
            <p>  In this work we present three novelties. (I) A large-scale synthetic <a href="https://cv.iri.upc-csic.es"><b>dataset</b></a> with photo-realistic images of 80 subjects  performing 70  activities and wearing  diverse  outfits. (II) A novel 3D body shape <b>representation</b> based on geometry images. (III) A <b>multi-resolution deep generative network</b> that, given an input  image of a dressed human, predicts his/her geometry image (and thus the clothed body shape) in an end-to-end manner.</p>
        </div>
          
        <h2 id="method"><a name="method">Dataset</a></h2>
          <center><iframe width="560" height="315" src="https://www.youtube.com/embed/6Rp44ks3WqM?autoplay=1" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></center>
          <center><div><a class="datasetbutton" href="https://cv.iri.upc-csic.es">Dataset Webpage</a></div></center>


            <p>First, we present 3DPeople, a large-scale synthetic dataset with 2.5 Million photo-realistic images of 80 subjects performing 70 activities and wearing diverse outfits. We annotate the dataset with segmentation masks, skeletons, depth, normal maps, optical flow and SMPL. We can NOT share the 3D meshes for copyright reasons. All this together makes 3DPeople suitable for a plethora of tasks.</p>

        <h2 id="method"><a name="method">Representation</a></h2>
            <center><img src="../../../images/2019/3DPeople/representation.jpg" alt="Geometry Image"></center>
            <p>We represent the 3D shapes using 2D geometry images. To build these images we propose a novel spherical area-preserving parameterization algorithm based on the optimal mass transportation method. We show this approach to improve existing spherical maps which tend to shrink the elongated parts of the full body models such as the arms and legs, making the geometry images incomplete. In the figure: (a) Reference mesh in a tpose configuration color coded using the xyz position. (b) Spherical parameterization; (c) Octahedral parameterization; (d) Unwarping the octahedron to a planar configuration; (e) Geometry image, resulting from the projection of the octahedron onto a plane; (f) mesh reconstructed from the geometry image.</p>
                
        <h2 id="method"><a name="method">Model</a></h2>
            <center><img src="../../../images/2019/3DPeople/model.jpg" alt="3DPeople"></center>
            <p>We also designed a multi-resolution deep generative network that, given an input image of a dressed human, predicts his/her geometry image (and thus the clothed body shape) in an end-to-end manner. We obtain very promising results in jointly capturing body pose and clothing shape, both for synthetic validation and on the wild images.</p>
            
        <h2 id="results"> 
        <a name="results">Results</a></h2>
        <center><img src="../../../images/2019/3DPeople/results.jpg" alt="3DPeople"></center>
        <div lang="en">
          <p>  Qualitative results. For the synthetic images we plot our estimated results and the shape reconstructed directly from the ground
              truth geometry image. In all cases we show two different views. The color of the meshes encodes the xyz vertex position.</p>
        </div>
        
        <h2><span lang="en">BibTex</span></h2>
        <div class="alert" lang="en">
            @inproceedings{pumarola20193dpeople,<br>
                &nbsp;&nbsp;&nbsp;&nbsp;title={{3DPeople: Modeling the Geometry of Dressed Humans}},<br>
                &nbsp;&nbsp;&nbsp;&nbsp;author={Pumarola, Albert and Sanchez, Jordi and Choi, Gary and Sanfeliu, Alberto and Moreno-Noguer, Francesc},<br>
                &nbsp;&nbsp;&nbsp;&nbsp;booktitle={International Conference on Computer Vision (ICCV)},<br>
                &nbsp;&nbsp;&nbsp;&nbsp;year={2019}<br>
            }
            
        </div>
        <h2><span lang="en">Publications</span></h2>
        <div class="publications">
        <h3 class="conference"><span lang="en">2019</span></h3>
        <ul class="publist">
     
          <li class="conference">
            <div class="details">
              <a href="https://arxiv.org/abs/1904.04571"><img src=
              "../../images/2019/3DPeople/thumbnail.png" height="194" width="131" alt=
              "3DPeople: Modeling the Geometry of Dressed Humans" id="3DPeople_arxiv" class="thumb"></a>
              <ul class="pub">
                <li class="pubtitle">3DPeople: Modeling the Geometry of Dressed Humans</li>
                  <li class="pubauthor">A. Pumarola, J. Sanchez, G. Choi, A. Sanfeliu and F. Moreno-Noguer</li> 
                <li class="pubbooktitle">International Conference on Computer Vision (ICCV), 2019 </li> 
                <li>
                 <div class="list_buttons">
                    <a class="bibtexLink" href="https://arxiv.org/abs/1904.04571" target="_blank">PDF</a>
                    <a class="bibtexLink" href="https://cv.iri.upc-csic.es">Dataset</a>
                    <a class="bibtexLink" href="https://github.com/albertpumarola/3DPeople-Dataset">Code</a>
                    <a class="bibtexLink" onclick="return toggle('/publications/Pumarola3DPeople2019/abs',this)"><span lang="en">Abstract</span></a>
                    <a class="bibtexLink" onclick="return toggle('/publications/Pumarola3DPeople2019/bib',this)">Bibtex</a>
                  </div>
                </li>
              </ul>
            </div>
            <div style="display: none;" class="abstractbox" id="/publications/Pumarola3DPeople2019/abs">
              <p>Recent advances in 3D human shape estimation build upon parametric representations that model very well the shape of the naked body, but are not appropriate to represent the clothing geometry. In this paper, we present an approach to model dressed humans and predict their geometry from single images. We contribute in three fundamental aspects of the problem, namely, a new dataset, a novel shape parameterization algorithm and an end-to-end deep generative network for predicting shape.First, we present 3DPeople, a large-scale synthetic dataset with 2.5 Million photo-realistic images of 80 subjects performing 70 activities and wearing diverse outfits. Besides providing textured 3D meshes for clothes and body, we annotate the dataset with segmentation masks, skeletons, depth, normal maps and optical flow. All this together makes 3DPeople suitable for a plethora of tasks. We then represent the 3D shapes using 2D geometry images. To build these images we propose a novel spherical area-preserving parameterization algorithm based on the optimal mass transportation method. We show this approach to improve existing spherical maps which tend to shrink the elongated parts of the full body models such as the arms and legs, making the geometry images incomplete. Finally, we design a multi-resolution deep generative network that, given an input image of a dressed human, predicts his/her geometry image (and thus the clothed body shape) in an end-to-end manner. We obtain very promising results in jointly capturing body pose and clothing shape, both for synthetic validation and on the wild images.</p>
            </div>
            <div style="display: none;" class="bibtex" id="/publications/Pumarola3DPeople2019/bib">
              <pre>@inproceedings{pumarola20193dpeople,
  title={{3DPeople: Modeling the Geometry of Dressed Humans}},
  author={Pumarola, Albert and Sanchez, Jordi and Choi, Gary and Sanfeliu, Alberto and Moreno-Noguer, Francesc},
  booktitle={International Conference on Computer Vision (ICCV)},
  year={2019}
}</pre>
            </div>
          </li>
        </ul>
    

        <div id="content">
          <div lang="en">
            <h2 id="model">Acknowledgments</h2>
            <p>This work is supported in part by an Amazon Research Award, the Croucher Foundation and the Spanish MiNeCo under projects HuMoUR TIN2017-90086-R, ColRobTransp DPI2016-78957-R  and Mar\'ia de Maeztu Seal of Excellence MDM-2016-0656. We also thank Nvidia for hardware donation under the GPU Grant Program. </p>
          </div>
        </div>
      </div>
    </div>
  </div>
  </div>  
      
  <script src="//ajax.googleapis.com/ajax/libs/jquery/3.1.1/jquery.min.js">
  </script> 
  <script>
  window.jQuery || document.write('<script src="../../../jquery.js"><\/script>')
  </script> 
  <script type="text/javascript" src="../../../site.js">
  </script> 
  <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-90616851-1', 'auto');
      ga('send', 'pageview');
  </script>
</body>
</html>
