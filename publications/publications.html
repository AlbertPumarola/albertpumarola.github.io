
<h1 lang="en">Publications</h1>
<ul id="filter" >
        <li><a href="#" data-val="all" class="current"><span lang="en">All</span></a></li>
<!--        <li><a id="top-button" href="#" data-val="top"><span lang="en">Top</span></a></li>-->
        <li><a href="#" data-val="journal"><span lang="en">Journal</span></a></li>
        <li><a href="#" data-val="conference"><span lang="en">Conference</span></a></li>
        <li><a href="#" data-val="workshop"><span lang="en">Workshop</span></a></li>
<!--        <li><a href="#" data-val="thesis"><span lang="en">Thesis</span></a></li>-->
      </ul>
<div class="publications">
        <h3 class="conference"><span lang="en">2017</span></h3>
        <ul class="publist">
          <li class="conference">
            <div class="details">
              <a href="../../publications/none.pdf" target="_blank"><img src=
              "../../images/2017/pl-slam/pl-slam_icra.jpg" height="110" width="110" alt=
              "Real-Time Monocular Visual SLAM with Points and Lines" class="thumb"></a>
              <ul class="pub">
                <li class="pubtitle">PL-SLAM: Real-Time Monocular Visual SLAM with Points and Lines</li>
                <li class="pubauthor">Albert Pumarola, Alexander Vakhitov, Antonio Agudo, Alberto Sanfeliu and Francesc Moreno-Noguer </li>
                <li class="pubbooktitle">IEEE International Conference on Robotics and Automation (ICRA), Singapore, 2017.</li>
                <li>
                  <div class="list_buttons">
                    <a class="bibtexLink" href="../research/pl-slam/index.html" target="_blank">Project Page</a>
                    <a class="bibtexLink" href="../../publications/none.pdf" target="_blank">PDF</a>
                    <a class="bibtexLink" onclick="return toggle('/publications/PumarolaICPR2017/abs',this)"><span lang="en">Abstract</span></a> 
                    <a class="bibtexLink" onclick="return toggle('/publications/PumarolaICPR2017/bib',this)">Bibtex</a>
                    <a class="bibtexLink" onclick="">code (to be released)</a>
                  </div>
                </li>
              </ul>
            </div>
            <div style="display: none;" class="abstractbox" id="/publications/PumarolaICPR2017/abs">
              <p>Low textured scenes are well known to be  one of the main Achilles heels of geometric computer vision algorithms relying on point correspondences, and in particular for visual SLAM. Yet, there are many environments in which, despite being low textured, one can still reliably estimate  line-based geometric primitives, for instance in  city and  indoor scenes, or in the so-called ``Manhattan worlds'', where structured edges are predominant. In this paper we propose a solution to handle these situations. Specifically, we build upon ORB-SLAM, presumably the  current state-of-the-art solution both in terms of accuracy as efficiency, and extend its formulation to simultaneously handle both point and line correspondences. We propose a solution that can even work when most of the  points are vanished out from the input images, and, interestingly it can be initialized from solely the detection of line correspondences in three consecutive frames. We thoroughly evaluate our approach and the new initialization strategy on the TUM RGB-D benchmark and demonstrate that the use of lines does not only improve the performance of the original ORB-SLAM solution in poorly textured frames, but also systematically improves it in sequence frames combining points and lines, without compromising the efficiency.</p>
            </div>
            <div style="display: none;" class="bibtex" id="/publications/PumarolaICPR2017/bib">
              <pre>@InProceedings{PumarolaICRA2017,
   author = {Albert Pumarola and Alexander Vakhitov and Antonio Agudo and Alberto Sanfeliu and Francesc Moreno-Noguer},
   title = {{PL-SLAM: Real-Time Monocular Visual SLAM with Points and Lines}},
   booktitle = "International Conference in Robotics and Automation (ICRA)",
   year = 2017
}</pre>
            </div>
          </li>
        </ul>
        <h3 class="journal"><span lang="en">2015</span></h3>
        <ul class="publist">
          <li class="journal">
            <div class="details">
              <a href="http://web.eecs.umich.edu/~soar/sitemaker/docs/pubs/Article_SOAR_GPSR-2.pdf" target="_blank"><img src=
              "../../images/2015/soar/soar.jpeg" height="110" width="110" alt=
              "Using a cognitive architecture for general purpose service robot control" class="thumb"></a>
              <ul class="pub">
                <li class="pubtitle">Using a cognitive architecture for general purpose service robot control</li>
                <li class="pubauthor">Jordi-Ysard Puigbo, Albert Pumarola, Cecilio Angulo, and Ricardo Tellez</li>
                <li class="pubbooktitle">Connection Science</li>
                <li>
                  <div class="list_buttons">
                    <a class="bibtexLink" href="http://web.eecs.umich.edu/~soar/sitemaker/docs/pubs/Article_SOAR_GPSR-2.pdf" target="_blank">PDF</a>
                    <a class="bibtexLink" href="https://www.youtube.com/watch?v=piCqb2O7rtU" target="_blank">Video</a>
                    <a class="bibtexLink" onclick="return toggle('/publications/puigbo2015using/abs',this)"><span lang="en">Abstract</span></a> 
                    <a class="bibtexLink" onclick="return toggle('/publications/puigbo2015using/bib',this)">Bibtex</a>
                  </div>
                </li>
              </ul>
            </div>
            <div style="display: none;" class="abstractbox" id="/publications/puigbo2015using/abs">
              <p>A humanoid service robot equipped with a set of simple action skills including navigating,
                    grasping, recognizing objects or people, among others, is considered in this paper. By using
                    those skills the robot should complete a voice command expressed in natural language encoding
                    a complex task (defined as the concatenation of a number of those basic skills). As a
                    main feature, no traditional planner has been used to decide skills to be activated, as well as
                    in which sequence. Instead, the SOAR cognitive architecture acts as the reasoner by selecting
                    which action the robot should complete, addressing it towards the goal. Our proposal allows
                    to include new goals for the robot just by adding new skills (without the need to encode new
                    plans). The proposed architecture has been tested on a human size humanoid robot, REEM,
                    acting as a general purpose service robot.</p>
            </div>
            <div style="display: none;" class="bibtex" id="/publications/puigbo2015using/bib">
              <pre>@article{puigbo2015using,
  title={Using a cognitive architecture for general purpose service robot control},
  author={Puigbo, Jordi-Ysard and Pumarola, Albert and Angulo, Cecilio and Tellez, Ricardo},
  journal={Connection Science},
  volume={27},
  number={2},
  pages={105--117},
  year={2015},
  publisher={Taylor \& Francis}
}</pre>
            </div>
          </li>
        </ul>
        <h3 class="workshop"><span lang="en">2014</span></h3>
        <ul class="publist">
          <li class="workshop">
            <div class="details">
              <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.402.5541&rep=rep1&type=pdf" target="_blank"><img src=
              "../../images/2014/soar/soar.jpeg" height="110" width="110" alt=
              "Controlling a General Purpose Service Robot By Means of a Cognitive Architecture." class="thumb"></a>
              <ul class="pub">
                <li class="pubtitle">Controlling a General Purpose Service Robot By Means of a Cognitive Architecture</li>
                <li class="pubauthor">Jordi-Ysard Puigbo1, Albert Pumarola, and Ricardo Tellez</li>
                <li class="pubbooktitle">AIC@ AI* IA</li>
                <li>
                  <div class="list_buttons">
                    <a class="bibtexLink" href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.402.5541&rep=rep1&type=pdf" target="_blank">PDF</a>
                    <a class="bibtexLink" href="https://www.youtube.com/watch?v=piCqb2O7rtU" target="_blank">Video</a>
                    <a class="bibtexLink" onclick="return toggle('/publications/puigbo2015using/abs',this)"><span lang="en">Abstract</span></a> 
                    <a class="bibtexLink" onclick="return toggle('/publications/puigbo2015using/bib',this)">Bibtex</a>
                  </div>
                </li>
              </ul>
            </div>
            <div style="display: none;" class="abstractbox" id="/publications/puigbo2013controlling/abs">
              <p>In this paper, a humanoid service robot is equipped with
                    a set of simple action skills including navigating, grasping, recognizing
                    objects or people, among others. By using those skills the robot has to
                    complete a voice command in natural language that encodes a complex
                    task (defined as the concatenation of several of those basic skills). To decide
                    which of those skills should be activated and in which sequence no
                    traditional planner has been used. Instead, the SOAR cognitive architecture
                    acts as the reasoner that selects the current action the robot must
                    do, moving it towards the goal. We tested it on a human size humanoid
                    robot Reem acting as a general purpose service robot. The architecture
                    allows to include new goals by just adding new skills (without having to
                    encode new plans)</p>
            </div>
            <div style="display: none;" class="bibtex" id="/publications/puigbo2013controlling/bib">
              <pre>@inproceedings{puigbo2013controlling,
  title={Controlling a General Purpose Service Robot By Means of a Cognitive Architecture.},
  author={Puigbo, Jordi-Ysard and Pumarola, Albert and T{\'e}llez, Ricardo A},
  organization={Citeseer}
}</pre>
            </div>
          </li>
        </ul>
      </div>
